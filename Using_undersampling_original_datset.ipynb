{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08349015-0cc1-4ce9-bca1-ba92d1e4de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9eb5a27-9a5b-4a68-8544-0b6d4980e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"uci-secom.csv\")\n",
    "\n",
    "# Identify and drop timestamp columns\n",
    "date_columns = [col for col in df.columns if \"time\" in col.lower()]\n",
    "df.drop(columns=date_columns, inplace=True, errors='ignore')\n",
    "\n",
    "# Data Cleaning: Remove columns with >80% missing values\n",
    "missing_threshold = 0.8\n",
    "df_cleaned = df.dropna(thresh=int((1 - missing_threshold) * df.shape[0]), axis=1)\n",
    "\n",
    "# Impute remaining missing values with median\n",
    "df_cleaned.fillna(df_cleaned.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f57a65-1ab3-4006-8f48-624539bb98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "df_cleaned.rename(columns={df_cleaned.columns[-1]: \"Pass/Fail\"}, inplace=True)\n",
    "\n",
    "# Split features and target\n",
    "X = df_cleaned.drop(columns=[\"Pass/Fail\"])\n",
    "y = df_cleaned[\"Pass/Fail\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Handle class imbalance with undersampling\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "majority_class = train_data[train_data[\"Pass/Fail\"] == -1]\n",
    "minority_class = train_data[train_data[\"Pass/Fail\"] == 1]\n",
    "majority_downsampled = resample(majority_class, replace=False, n_samples=len(minority_class), random_state=42)\n",
    "balanced_train_data = pd.concat([majority_downsampled, minority_class])\n",
    "\n",
    "# Separate features and target after balancing\n",
    "X_train_balanced = balanced_train_data.drop(columns=[\"Pass/Fail\"])\n",
    "y_train_balanced = balanced_train_data[\"Pass/Fail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a43e90cc-0e98-4f52-939e-940ad4dc757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3c69afa-3140-44d1-8050-14f8ce553cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"NaiveBayes\": GaussianNB()\n",
    "}\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, 20]},\n",
    "    \"SVM\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]},\n",
    "    \"NaiveBayes\": {}  # No hyperparameters for Naïve Bayes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e741a9d3-d70e-44fa-870f-52d5be76322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n",
      "RandomForest Training Complete.\n",
      "\n",
      "Training SVM...\n",
      "SVM Training Complete.\n",
      "\n",
      "Training NaiveBayes...\n",
      "NaiveBayes Training Complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "best_models = {}\n",
    "classification_reports = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    if param_grids[name]:\n",
    "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "        grid_search.fit(X_train_scaled, y_train_balanced)\n",
    "        best_model = grid_search.best_estimator_\n",
    "    else:\n",
    "        best_model = model.fit(X_train_scaled, y_train_balanced)\n",
    "    \n",
    "    best_models[name] = best_model\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    classification_reports[name] = classification_report(y_test, y_pred)\n",
    "    print(f\"{name} Training Complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ced5a74-b4c2-4e78-8b75-78974dd0149f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.75      0.84       293\n",
      "           1       0.16      0.67      0.26        21\n",
      "\n",
      "    accuracy                           0.74       314\n",
      "   macro avg       0.56      0.71      0.55       314\n",
      "weighted avg       0.91      0.74      0.80       314\n",
      "\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.60      0.74       293\n",
      "           1       0.11      0.67      0.18        21\n",
      "\n",
      "    accuracy                           0.60       314\n",
      "   macro avg       0.53      0.63      0.46       314\n",
      "weighted avg       0.90      0.60      0.70       314\n",
      "\n",
      "\n",
      "NaiveBayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.94      0.94       293\n",
      "           1       0.21      0.24      0.22        21\n",
      "\n",
      "    accuracy                           0.89       314\n",
      "   macro avg       0.58      0.59      0.58       314\n",
      "weighted avg       0.90      0.89      0.89       314\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification reports\n",
    "for name, report in classification_reports.items():\n",
    "    print(f\"{name} Classification Report:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37dbc1df-60ac-4dbe-bf0e-14603495e70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best model\n",
    "import joblib\n",
    "joblib.dump(best_models[\"RandomForest\"], \"best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c549e49-c8ea-4da6-8b0f-091af7ec546f",
   "metadata": {},
   "source": [
    "# Model Performance Comparison\n",
    "\n",
    "## Random Forest:\n",
    "- **Pass (-1) Class:** Good precision (0.97), but recall is only 0.75.\n",
    "- **Fail (1) Class:** Low precision (0.16), but decent recall (0.67).\n",
    "- **Overall:** Balanced model but still biased towards \"Pass\" cases.\n",
    "\n",
    "## SVM:\n",
    "- **Pass (-1) Class:** Precision (0.96), recall (0.60), meaning it struggles to capture all \"Pass\" cases.\n",
    "- **Fail (1) Class:** Precision (0.11), recall (0.67), meaning it captures many \"Fail\" cases but with high false positives.\n",
    "- **Overall:** Poor performance compared to Random Forest.\n",
    "\n",
    "## Naïve Bayes:\n",
    "- **Pass (-1) Class:** Excellent precision & recall (0.94 each).\n",
    "- **Fail (1) Class:** Precision (0.21), recall (0.24), meaning it poorly identifies \"Fail\" cases.\n",
    "- **Overall:** High accuracy (89%), but very weak in detecting the minority class.\n",
    "\n",
    "## Conclusion:\n",
    "- **Best model:** Random Forest (better balance between classes).\n",
    "- **Weakest model:** SVM (lowest accuracy and performance).\n",
    "- **Naïve Bayes:** Works well for \"Pass\" class but ignores \"Fail\" cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3bb32-c214-4ac5-997c-35114ac45089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
