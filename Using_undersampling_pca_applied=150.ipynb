{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30db9479-2640-4b36-b5ca-9feb2a6fdaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7339f3a4-2c9d-4432-9d27-1766f57f1835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"uci-secom.csv\")\n",
    "\n",
    "# Identify and drop timestamp columns\n",
    "date_columns = [col for col in df.columns if \"time\" in col.lower()]\n",
    "df.drop(columns=date_columns, inplace=True, errors='ignore')\n",
    "\n",
    "# Data Cleaning: Remove columns with >80% missing values\n",
    "missing_threshold = 0.8\n",
    "df_cleaned = df.dropna(thresh=int((1 - missing_threshold) * df.shape[0]), axis=1)\n",
    "\n",
    "# Impute remaining missing values with median\n",
    "df_cleaned.fillna(df_cleaned.median(), inplace=True)\n",
    "\n",
    "# Define target variable\n",
    "df_cleaned.rename(columns={df_cleaned.columns[-1]: \"Pass/Fail\"}, inplace=True)\n",
    "\n",
    "# Split features and target\n",
    "X = df_cleaned.drop(columns=[\"Pass/Fail\"])\n",
    "y = df_cleaned[\"Pass/Fail\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Handle class imbalance with undersampling\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "majority_class = train_data[train_data[\"Pass/Fail\"] == -1]\n",
    "minority_class = train_data[train_data[\"Pass/Fail\"] == 1]\n",
    "majority_downsampled = resample(majority_class, replace=False, n_samples=len(minority_class), random_state=42)\n",
    "balanced_train_data = pd.concat([majority_downsampled, minority_class])\n",
    "\n",
    "# Separate features and target after balancing\n",
    "X_train_balanced = balanced_train_data.drop(columns=[\"Pass/Fail\"])\n",
    "y_train_balanced = balanced_train_data[\"Pass/Fail\"]\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b5312d4-3923-4f53-b39e-7e57b78bfdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest on PCA data...\n",
      "RandomForest Training on PCA Complete.\n",
      "\n",
      "Training SVM on PCA data...\n",
      "SVM Training on PCA Complete.\n",
      "\n",
      "Training NaiveBayes on PCA data...\n",
      "NaiveBayes Training on PCA Complete.\n",
      "\n",
      "RandomForest Classification Report (After PCA):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.78      0.86       293\n",
      "           1       0.12      0.43      0.19        21\n",
      "\n",
      "    accuracy                           0.76       314\n",
      "   macro avg       0.54      0.61      0.53       314\n",
      "weighted avg       0.90      0.76      0.82       314\n",
      "\n",
      "\n",
      "SVM Classification Report (After PCA):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.00      0.01       293\n",
      "           1       0.07      1.00      0.13        21\n",
      "\n",
      "    accuracy                           0.07       314\n",
      "   macro avg       0.53      0.50      0.07       314\n",
      "weighted avg       0.94      0.07      0.01       314\n",
      "\n",
      "\n",
      "NaiveBayes Classification Report (After PCA):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.95      0.94       293\n",
      "           1       0.17      0.14      0.15        21\n",
      "\n",
      "    accuracy                           0.89       314\n",
      "   macro avg       0.55      0.55      0.55       314\n",
      "weighted avg       0.89      0.89      0.89       314\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_model_pca.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply PCA for dimensionality reduction before model training\n",
    "pca = PCA(n_components=150)  # Keep 150 principal components\n",
    "X_train_pca = pca.fit_transform(X_train_balanced)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Standardization after PCA\n",
    "X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
    "X_test_pca_scaled = scaler.transform(X_test_pca)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"NaiveBayes\": GaussianNB()\n",
    "}\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, 20]},\n",
    "    \"SVM\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]},\n",
    "    \"NaiveBayes\": {}  # No hyperparameters for Naïve Bayes\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "best_models_pca = {}\n",
    "classification_reports_pca = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} on PCA data...\")\n",
    "    model.fit(X_train_pca_scaled, y_train_balanced)\n",
    "    \n",
    "    y_pred_pca = model.predict(X_test_pca_scaled)\n",
    "    \n",
    "    best_models_pca[name] = model\n",
    "    classification_reports_pca[name] = classification_report(y_test, y_pred_pca)\n",
    "\n",
    "    print(f\"{name} Training on PCA Complete.\\n\")\n",
    "\n",
    "# Display classification reports\n",
    "for name, report in classification_reports_pca.items():\n",
    "    print(f\"{name} Classification Report (After PCA):\\n{report}\\n\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_models_pca[\"RandomForest\"], \"best_model_pca.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16146c36-22df-4227-9578-2cc26a109bbb",
   "metadata": {},
   "source": [
    "# Model Performance Comparison (After PCA with 150 Components)\n",
    "\n",
    "## Random Forest:\n",
    "- **Pass (-1) Class:** Precision (0.95), recall (0.78), indicating strong precision but some missed \"Pass\" cases.\n",
    "- **Fail (1) Class:** Precision (0.12), recall (0.43), meaning it identifies some \"Fail\" cases but with high false positives.\n",
    "- **Overall:** Accuracy (76%)—a more balanced model but still favors the majority class.\n",
    "\n",
    "## SVM:\n",
    "- **Pass (-1) Class:** Precision (1.00), recall (0.00), meaning it predicts all cases as \"Pass\" but fails to recall any.\n",
    "- **Fail (1) Class:** Precision (0.07), recall (1.00), meaning it captures all \"Fail\" cases but at the cost of extreme false positives.\n",
    "- **Overall:** Accuracy (7%)—completely ineffective for classification.\n",
    "\n",
    "## Naïve Bayes:\n",
    "- **Pass (-1) Class:** Precision (0.94), recall (0.95), showing strong classification for \"Pass\" cases.\n",
    "- **Fail (1) Class:** Precision (0.17), recall (0.14), meaning it struggles to identify \"Fail\" cases.\n",
    "- **Overall:** Accuracy (89%)—performs well overall but poorly for the minority class.\n",
    "\n",
    "## Conclusion:\n",
    "- **Best model:** Random Forest (better recall for \"Pass\" class and reasonable balance).\n",
    "- **Weakest model:** SVM (fails to classify properly, extreme bias).\n",
    "- **Naïve Bayes:** Effective for \"Pass\" cases but weak in identifying \"Fail\" cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93698bd8-d72a-4c51-8b95-d3a352aa6e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
